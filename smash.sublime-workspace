{
	"auto_complete":
	{
		"selected_items":
		[
			[
				"fill",
				"fill_gaps_in_dt"
			],
			[
				"fil",
				"fill_gaps_in_dt"
			],
			[
				"wmag_",
				"wmag_pro_mean_day"
			],
			[
				"write",
				"write_xcsv"
			],
			[
				"Va",
				"Van_231_Table440"
			],
			[
				"query_the",
				"query_the_database_5"
			],
			[
				"Bio",
				"Biomasser2〔class〕"
			],
			[
				"merge",
				"merge_population_and_graveyard  (function)"
			],
			[
				"Pl",
				"PlotInstance  (class)"
			]
		]
	},
	"buffers":
	[
		{
			"file": "smashWorkers.py",
			"settings":
			{
				"buffer_size": 262152,
				"line_ending": "Unix"
			}
		},
		{
			"contents": "import form_connection as fc\nimport pymssql\nimport csv\nimport datetime\nimport math\nimport yaml\nimport numpy as np\nimport itertools\nimport smashControls\nimport argparse\n\nclass ProbeBoss(object):\n    \"\"\" The smashBosses are responsible for conducting specific data queries, such as generating probe-specific outputs \"\"\"\n\n    def __init__(self, attribute, server, vpd=\"off\"):\n        \"\"\" initialize the boss with a configuration file and an attribute\"\"\"\n\n        # limits is the config\n        self.limits = yaml.load(open('LIMITED.yaml','rb'))\n        # attribute you give\n        self.attribute = attribute\n        # server is either sheldon or stewartia\n        self.server = server\n        # startdate is the day it begins\n        self.startdate = ''\n        # end date is the day it ends\n        self.enddate = ''\n        # vpd is a kwarg- if it's \"off\" then nothing happens. if it's \"on\" we use the special computation. we change the default when we change method\n        self.vpd = vpd\n\n    def get_one_config(self, chosen_probe):\n        \"\"\" get one configuration - that means 1 probe over 1 set of time stamps, i.e. AIRPRI01 between say january 2 2015 and february 22, 2015. or VPDCEN04 between april 5 2015 and april 10 2015. This doesn't get all the probes at once! But note that by default in the controller dew and vpd are checked for bad dates. \"\"\"\n\n        # compute the startdate and end date as strings if they are not already strings!\n        self.startdate = datetime.datetime.strftime(self.limits[chosen_probe]['startdate'], '%Y-%m-%d %H:%M:%S')\n        self.enddate = datetime.datetime.strftime(self.limits[chosen_probe]['enddate'], '%Y-%m-%d %H:%M:%S')\n        \n        # if it is not VPD, then go ahead and make a worker\n        if self.attribute != \"VPD\":\n            myWorker = smashControls.Worker(self.attribute, self.startdate, self.enddate, self.server, chosen_probe)\n\n        # if it is VPD but we are using the old method, then go ahead and make a worker\n        elif self.attribute == \"VPD\" and self.vpd == \"off\":\n            myWorker = smashControls.Worker(self.attribute, self.startdate, self.enddate, self.server, chosen_probe)\n\n        # if it is VPD and we are using the new method, then we assign that to the worker\n        elif self.attribute == \"VPD\" and self.vpd == \"on\":\n            myWorker = smashControls.VaporControl(self.startdate, self.enddate, self.server, chosen_probe)\n\n        # my worker is one worker object\n        return myWorker\n\n    @staticmethod\n    def write_one_worker_to_csv(myWorker, *args):\n        \"\"\" open a csvfile and write out one data - this is in a sense just doing one probe to one csv, for the purpose of maybe patching something\"\"\"\n        \n        with open(myWorker.HeaderWriter.filename, 'wb') as writefile:\n            writer = csv.writer(writefile, quoting = csv.QUOTE_NONNUMERIC, delimiter = \",\")\n\n            myHeader = myWorker.HeaderWriter.write_header_template()\n            \n            writer.writerow(myHeader)\n\n            if args:\n                try:\n                    my_new_rows = myWorker.Worker.condense_data(args[0])\n                except Exception:\n                    my_new_rows = myWorker.condense_data(args[0])\n            \n            else:\n                try:\n                    my_new_rows = myWorker.Worker.condense_data()\n                except Exception:\n                    my_new_rows = myWorker.condense_data()\n            \n            for row in my_new_rows:\n\n                writer.writerow(row)\n\n\n    def iterate_over_many_config(self, *args):\n        \"\"\" walks over the limits file and creates for each a worker, who then goes and gets the data for each and writes it to a single csv output\"\"\"\n        \n        import smashWorkers\n\n        # writes the csv-headers\n        templateWorker = smashWorkers.HeaderWriter(self.attribute)\n\n        # writing to the csv\n        with open(templateWorker.filename, 'wb') as writefile:\n                \n            writer = csv.writer(writefile, quoting = csv.QUOTE_NONNUMERIC, delimiter = \",\")\n\n            myHeader = templateWorker.write_header_template()\n            \n            writer.writerow(myHeader)\n\n            # for the prose you choose\n            for chosen_probe in self.limits.keys():\n\n                # get that worker\n                myWorker = self.get_one_config(chosen_probe)\n\n                # if you need the custom configuration, use it\n                if args:\n                    my_new_rows = myWorker.Worker.condense_data(args[0])\n                else:\n                    my_new_rows = myWorker.Worker.condense_data()\n\n                # write the rows, then delete the worker\n                for row in my_new_rows:\n                    writer.writerow(row)\n\n                del myWorker\n\n        print(\"Finished writing data to \" + templateWorker.filename)\n\n\nclass UpdateBoss(object):\n    \"\"\" The UpdateBoss updates an attribute based on the times you specify\"\"\"\n\n    def __init__(self, attribute, startdate, enddate, server, vpd=\"off\"):\n        \n        self.attribute = attribute\n        self.startdate = startdate\n        self.enddate = enddate\n        self.server = server\n        self.vpd = vpd\n\n        # if it is not VPD, then go ahead and make a worker\n        if self.attribute != \"VPD\":\n            self.myWorker = smashControls.Worker(self.attribute, self.startdate, self.enddate, self.server)\n            \n            self.new_rows = self.myWorker.Worker.condense_data()\n\n            if self.myWorker.Worker.entity < 10:\n                new_string = \"0\"+str(self.myWorker.Worker.entity)\n            else:\n                new_string = str(self.myWorker.Worker.entity)\n\n            # name of the table\n            self.table = 'MS043' + new_string\n\n        # if it is VPD but we are using the old method, then go ahead and make a worker\n        elif self.attribute == \"VPD\" and self.vpd == \"off\":\n            self.myWorker = smashControls.Worker(self.attribute, self.startdate, self.enddate, self.server)\n            self.new_rows = self.myWorker.Worker.condense_data()\n\n            if self.myWorker.Worker.entity < 10:\n                new_string = \"0\"+str(self.myWorker.Worker.entity)\n            else:\n                new_string = str(self.myWorker.Worker.entity)\n\n\n            # name of the table\n            self.table = 'MS043' + new_string\n\n        # if it is VPD and we are using the new method, then we assign that to the worker\n        elif self.attribute == \"VPD\" and self.vpd == \"on\":\n            self.myWorker = smashControls.VaporControl(self.startdate, self.enddate, self.server)\n            self.new_rows = self.myWorker.condense_data()\n\n            # name of the table\n            self.table = 'MS04308'\n        \n        else: \n            print \"this will never get called\"\n\n    def only_one_station(self, station):\n\n        h = [self.new_rows[index] for index, row in enumerate(self.new_rows) if self.new_rows[index][2] == station]\n\n        return h\n\n    def update_the_db(self):\n        \"\"\" Updates LTER Logger Pro-- NOT LTER LOGGER NEW! -- currently as of 04-20-3015 its empty so I can't check it for pre-existing values without an error! \"\"\"\n        print(\"This is gonna update the LTERLogger_Pro database\")\n\n        # form a new connection (we need this because we need the conn object to commit)\n        import form_connection as fc\n        conn = fc.micro_conn('SHELDON')\n\n        # keep the tuples from the previous analysis\n        new_tuples = [tuple(x) for x in self.new_rows]\n\n        \n        cursor = conn.cursor()\n        # get_the_column_names\n        cursor.execute(\"select column_name from LTERLogger_Pro.information_schema.columns where table_name like \\'\" + self.table + \"\\' and table_schema like 'dbo'\")\n\n        print( \" your execution query was: \\n SELECT column_name from LTERLogger_Pro.information_schema.columns where table_name like \\'\" + self.table + \"\\' and table_schema like 'dbo'\")\n\n\n        # make 'em ' into a list\n        nr = []\n        for row in cursor:\n            nr.append(str(row[0]))\n\n\n        if self.attribute != \"NR\":\n            column_string = \" ,\".join(nr[:-1])\n        elif self.attribute == \"NR\":\n            column_string = \" ,\".join(nr)\n\n                \n        # for some reason it likes to use \"d\" which is not the usual \"f\" formatter for doing floats. Yes, a total mystery. Example of working prototype        \n        # cursor.executemany(\"insert into LTERLogger_Pro.dbo.Test (CreateTime, DValue) VALUES (%s, %d)\", [('2015-01-02 00:00:00', 17.343823), ('2015-01-03 00:00:00', 18.238123), ('2015-01-04 00:00:00', 23.328)])\n\n        if self.attribute in [\"AIRTEMP\", \"RELHUM\", \"DEWPT\", \"SOILTEMP\", \"SOILWC\"]:\n        \n            cursor.executemany(\"insert into LTERLogger_Pro.dbo.\" + self.table +\" (\" + column_string + \") VALUES (%s, %d, %s, %s, %d, %s, %s, %s, %d, %s, %d, %s, %s, %d, %s, %s, %s, %s)\", new_tuples)\n\n            conn.commit()\n\n        elif self.attribute in \"VPD\":\n\n            cursor.executemany(\"insert into LTERLogger_Pro.dbo.\" + self.table + \" (\" + column_string + \") VALUES (%s, %d, %s, %s, %d, %s, %s, %s, %d, %s, %d, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\", new_tuples)\n\n            conn.commit()\n\n        elif self.attribute in \"SOLAR\":\n\n            cursor.executemany(\"insert into LTERLogger_Pro.dbo.\" + self.table +\" (\" + column_string + \")  VALUES (%s, %d, %s, %s, %d, %s, %s, %s, %d, %s, %d, %s, %d, %s, %s, %s, %s)\", new_tuples)\n            conn.commit()\n\n        elif self.attribute in \"PRECIP\":\n\n            cursor.executemany(\"insert into LTERLogger_Pro.dbo\" + self.table + \" (\" + column_string + \") VALUES( %s, %d, %s, %s, %d, %s, %s, %s, %d, %s, %d , %s,  %s, %s)\", new_tuples)\n            conn.commit()\n\n        elif self.attribute in \"LYS\":\n\n           cursor.executemany(\"insert into LTERLogger_Pro.dbo\" + self.table + \" (\" + column_string + \") VALUES( %s, %d, %s, %s, %s, %s, %s, %d, %s, %d , %s, %s, %s)\", new_tuples)\n\n           conn.commit()\n\n        elif self.attribute in \"PAR\":\n            \n            cursor.executemany(\"insert into LTERLogger_Pro.dbo\" + self.table + \" (\" + column_string + \") VALUES (%s, %d, %s, %s, %d, %s, %s, %s, %d, %s, %d, %s, %d, %s, %s)\", new_tuples)\n            conn.commit()\n\n        elif self.attribute in \"NR\":\n            \n            cursor.executemany(\"insert into LTERLogger_Pro.dbo.\" + self.table + \" (\" + column_string + \")  VALUES (%s, %d, %s, %s, %d, %s, %s, %s, %d, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\", new_tuples)\n\n            conn.commit()\n\n\n        elif self.attribute in \"WSPD_PRO\":\n            cursor.executemany(\"insert into LTERLogger_Pro.dbo.\" + self.table + \" (\" + column_string + \")  VALUES(%s, %d, %s, %s, %d, %s, %s, %s, %d, %s, %d, %s, %d,%s ,%s, %d, %s, %d, %s, %d,  %s, %d, %s, %d, %s, %d, %s, %d, %s, %d, %s, %d, %s, %d, %s, %s, %s)\", new_tuples)\n\n            conn.commit()\n        \n        elif self.attribute in \"WSPD_SNC\":\n            cursor.executemany(\"insert into LTERLogger_Pro.dbo.\" + self.table + \" (\" + column_string + \")  VALUES( %s,  %d,  %s, %s,  %d,  %s, %s,  %s,    %d,  %s,  %d,  %s,  %d, %s,  %d, %s,    %d, %s,   %d, %s, %d,   %s,   %d,  %s, %d   %s,  %d, %s,  %s,  %s)\",new_tuples)\n\n            conn.commit()\n    \n    def write_a_csv(self):\n        \"\"\" writes the rows in self.new_rows to a csv\"\"\"\n        import smashWorkers\n        templateWorker = smashWorkers.HeaderWriter(self.attribute)\n        \n        filename = self.table + \"_\" + self.server + \"_temp.csv\"\n        with open(filename,'wb') as writefile:\n\n            writer = csv.writer(writefile, quoting = csv.QUOTE_NONNUMERIC, delimiter = \",\")\n\n            myHeader = templateWorker.write_header_template()\n            \n            writer.writerow(myHeader)\n\n            for row in self.new_rows:\n                writer.writerow(row)\n\nclass MethodBoss(object):\n    \"\"\" uses the file from don for updating the LterLogger_Pro\"\"\"\n    def __init__(self, attribute):\n\n        self.filename = \"method_current_daily.CSV\"\n        self.attribute = attribute\n        self.od = self.csv_to_dict()\n\n    def csv_to_dict(self):\n        \"\"\" update method list is imported. \"\"\"\n        od = {}\n\n        with open(self.filename, 'rb') as readfile:\n            reader = csv.reader(readfile)\n\n            for row in reader:\n\n                if str(row[1]) not in od:\n                    # make start, end, and method update-able\n                    od[str(row[1])] = {'startdate': [str(row[2])], 'enddate': [str(row[3])], 'height': str(row[4]), 'method_code':[str(row[6])], 'site_code': str(row[0])}\n                elif str(row[1]) in od:\n                    od[str(row[1])]['startdate'].append(str(row[2]))\n                    od[str(row[1])]['enddate'].append(str(row[3]))\n                    od[str(row[1])]['method_code'].append(str(row[6]))\n                else: \n                    pass\n\n        return od\n\n    def update_methods(self):\n\n        import form_connection as fc\n        conn = fc.micro_conn('SHELDON')\n\n        cursor = conn.cursor()\n\n        query_d = {'AIRTEMP': 'MS04301',\n                    'RELHUM': 'MS04302',\n                    'PRECIP': 'MS04303',\n                    'WSPD_PRO': 'MS04304',\n                    'SOLAR': 'MS04305',\n                    'DEWPT': 'MS04307',\n                    'VPD': 'MS04308',\n                    'LYS': 'MS04309',\n                    'NR': 'MS04325',\n                    'WSPD_SNC': 'MS04324',\n                    'SOILTEMP': 'MS04321',\n                    'SOILWC': 'MS04323',\n                    'PAR': 'MS04322'}\n\n\n        valid_keys = []\n        if self.attribute == \"AIRTEMP\":\n\n            for key in self.od.keys():\n\n                if \"AIR\" in key:\n                    valid_keys.append(key)\n\n        elif self.attribute == \"RELHUM\":\n\n            for key in self.od.keys():\n\n                if \"REL\" in key:\n                    valid_keys.append(key)\n\n\n        elif self.attribute == \"PRECIP\":\n            for key in self.od.keys():\n\n                    if \"PPT\" in key:\n                        valid_keys.append(key)\n\n        elif self.attribute == \"WSPD_SNC\":\n\n\n            valid_keys = [\"WNDPRI02\", \"WNDVAN02\"]\n\n\n        elif self.attribute == \"WSPD_PRO\":\n\n            valid_keys = [\"WNDPRI01\", \"WNDVAN01\", \"WNDUPL01\", \"WNDCEN01\", \"WNDH1501\"]\n\n\n        elif self.attribute == \"DEWPT\":\n            for key in self.od.keys():\n\n                if \"DEW\" in key:\n                    valid_keys.append(key)\n\n        elif self.attribute == \"VPD\":\n            for key in self.od.keys():\n\n                if \"VPD\" in key:\n                    valid_keys.append(key)\n\n        elif self.attribute in \"SOLAR\":\n\n            valid_keys = [\"RADPRI01\",\"RADVAN01\",\"RADUPL01\",\"RADCEN01\"]\n\n        elif self.attribute in \"NR\":\n\n            valid_keys = [\"RADPRI02\",\"RADVAN02\"]\n\n        elif self.attribute in \"SOILWC\":\n            for key in self.od.keys():\n\n                if \"SWC\" in key:\n                    valid_keys.append(key)\n\n        elif self.attribute in \"SOILTEMP\":\n            for key in self.od.keys():\n\n                if \"SOI\" in key:\n                    valid_keys.append(key)\n\n\n        elif self.attribute in \"LYS\":\n\n            for key in self.od.keys():\n                if \"LYS\" in key:\n                    valid_keys.append(key)\n\n        else:\n            pass\n\n        if valid_keys != []:\n\n            for each_key in valid_keys:\n\n                startdate = self.od[each_key]['startdate'][0]\n                enddate = self.od[each_key]['enddate'][0]\n                new_method_code = self.od[each_key]['method_code'][0]\n            \n                new_query = \"update LTERLogger_Pro.dbo.\" + query_d[self.attribute] + \" set \" + self.attribute + \"_METHOD = \\'\" +  str(new_method_code) + \"\\' where probe_code like \\'\" + each_key + \"\\' and Date >= \\'\" + startdate + \"\\' and Date < \\'\" + enddate + \"\\'\"\n\n                print new_query\n\n                cursor.execute(new_query)   \n\n            conn.commit() \n        else:\n            print \"nothing to commit!\"\n\n\n# class MethodBoss2(object):\n\n#     self.filename = \"method_current_hires.csv\"\n#     self.d = self.get_highres()\n\n#     def get_highres(self):\n#         d = {}\n#         with open('method_current_hires.csv','rb') as readfile:\n#             reader = csv.reader(readfile)\n#             for row in reader:\n#                 if str(row[1]) not in d:\n#                     d[str(row[1])] = {'startdate': str(row[2]), 'enddate':str(row[3]), 'res': str(row[6]), 'hrmethod': str(row[7])}\n#                 elif str(row[1]) in d:\n#                     print \"huh\"\n#         return d\n\n#     def update_methods(self):\n\n#         import form_connection as fc\n#         conn = fc.micro_conn('SHELDON')\n\n#         cursor = conn.cursor()\n\n#         query_d = {'AIRTEMP': 'MS04301',\n#                     'RELHUM': 'MS04302',\n#                     'PRECIP': 'MS04303',\n#                     'WSPD_PRO': 'MS04304',\n#                     'SOLAR': 'MS04305',\n#                     'DEWPT': 'MS04307',\n#                     'VPD': 'MS04308',\n#                     'LYS': 'MS04309',\n#                     'NR': 'MS04325',\n#                     'WSPD_SNC': 'MS04324',\n#                     'SOILTEMP': 'MS04321',\n#                     'SOILWC': 'MS04323',\n#                     'PAR': 'MS04322'}\n\n#         valid_keys = []\n        \n#         if self.attribute == \"AIRTEMP\":\n\n#             for key in self.d.keys():\n\n#                 if \"AIR\" in key:\n#                     valid_keys.append(key)\n\n#         elif self.attribute == \"RELHUM\":\n\n#             for key in self.d.keys():\n\n#                 if \"REL\" in key:\n#                     valid_keys.append(key)\n\n\n#         elif self.attribute == \"PRECIP\":\n#             for key in self.d.keys():\n\n#                 if \"PPT\" in key:\n#                     valid_keys.append(key)\n\n#         elif self.attribute == \"WSPD_SNC\":\n\n\n#             valid_keys = [\"WNDPRI02\", \"WNDVAN02\"]\n\n\n#         elif self.attribute == \"WSPD_PRO\":\n\n#             valid_keys = [\"WNDPRI01\", \"WNDVAN01\", \"WNDUPL01\", \"WNDCEN01\", \"WNDH1501\"]\n\n\n#         elif self.attribute == \"DEWPT\":\n#             for key in self.d.keys():\n\n#                 if \"DEW\" in key:\n#                     valid_keys.append(key)\n\n#         elif self.attribute == \"VPD\":\n#             for key in self.d.keys():\n\n#                 if \"VPD\" in key:\n#                     valid_keys.append(key)\n\n#         elif self.attribute in \"SOLAR\":\n\n#             valid_keys = [\"RADPRI01\",\"RADVAN01\",\"RADUPL01\",\"RADCEN01\"]\n\n#         elif self.attribute in \"NR\":\n\n#             valid_keys = [\"RADPRI02\",\"RADVAN02\"]\n\n#         elif self.attribute in \"SOILWC\":\n#             for key in self.d.keys():\n\n#                 if \"SWC\" in key:\n#                     valid_keys.append(key)\n\n#         elif self.attribute in \"SOILTEMP\":\n#             for key in self.d.keys():\n\n#                 if \"SOI\" in key:\n#                     valid_keys.append(key)\n\n\n#         elif self.attribute in \"LYS\":\n\n#             for key in self.d.keys():\n#                 if \"LYS\" in key:\n#                     valid_keys.append(key)\n\n#         else:\n#             pass\n\n#         if valid_keys != []:\n\n#             for each_key in valid_keys:\n\n#                 startdate = self.d[each_key]['startdate']\n#                 enddate = self.d[each_key]['enddate']\n#                 res = self.d[each_key]['res']\n\n#                 if res == \"15 minutes\":\n#                     replace_flag = \"F\"\n#                 elif res == \"60 minutes\":\n#                     replace_flag = \"H\"\n#                 else:\n#                     continue\n                \n#                 # check for max and min sets\n#                 if self.attribute in [\"AIRTEMP\", \"RELHUM\", \"WSPD_PRO\", \"SOLAR\", \"DEWPT\", \"VPD\", \"SOILTEMP\", \"SOILWC\", \"PAR\", \"WSPD_SNC\"]:\n                    \n#                     ### Update max flag to new replacement\n#                     new_query = \"update LTERLogger_Pro.dbo.\" + query_d[self.attribute] + \" set \" + self.attribute + \"_MAX_FLAG = \\'\" +  replace_flag + \"\\' where probe_code like \\'\" + each_key + \"\\' and Date >= \\'\" + startdate + \"\\' and Date < \\'\" + enddate + \"\\'\"\n\n#                     cursor.execute(new_query) \n\n\n#                 if self.attribute in [\"AIRTEMP\", \"DEWPT\", \"VPD\", \"SOILTEMP\", \"SOILWC\"]:\n                    \n#                     # update min flag to new replacement\n#                     new_query = \"update LTERLogger_Pro.dbo.\" + query_d[self.attribute] + \" set \" + self.attribute + \"_MIN_FLAG = \\'\" +  replace_flag + \"\\' where probe_code like \\'\" + each_key + \"\\' and Date >= \\'\" + startdate + \"\\' and Date < \\'\" + enddate + \"\\'\"\n \n#                     cursor.execute(new_query)\n\n            \n#             # commit the changes\n#             conn.commit() \n        \n#         else:\n#             print \"nothing to commit!\"",
			"file": "smashBosses.py",
			"file_size": 20825,
			"file_write_time": 1430347439000000,
			"settings":
			{
				"buffer_size": 20824,
				"line_ending": "Unix"
			}
		},
		{
			"file": "smashControls.py",
			"settings":
			{
				"buffer_size": 21434,
				"line_ending": "Unix"
			}
		},
		{
			"contents": "import argparse\nimport smashBosses\nimport smashControls\nimport datetime\n\n\"\"\"SMASHER is the executable for the other parts of the data 'smashing'. The smasher bash program will run all of the update bosses in a row, for one day.\n\nThe SMASHER API is designed to ease the updating of FSDBDATA and LTERLogger_Pro, as well as the import of high resolution data into MS043.\n\n\nMain commands: 'XXDEL' (deletes all after a certain date), 'XXDEL1' (deletes one station between a set of dates), 'HANS' (runs in a flow)\n\"\"\"\n\nparser = argparse.ArgumentParser(description=\"SMASHER tool for FSDB summaries. Use the SMASHER bosses within a bash file or on the API to conduct controlled summaries. SMASHER bosses are superclasses with controlled operations and vocabularies. SMASHER controls are switch statements designed to drive SMASHER bosses. SMASHER workers are microprocesses designed to work with high-resolution data in the FSDB structure.\")\n\n# which function you are running -- REQUIRED!\nparser.add_argument('boss')\n\n# which server you are using -- REQUIRED!\nparser.add_argument('server')\n\n# which attribute you are using \nparser.add_argument('--attribute', '-a', nargs = 1, required = False, help = \" the official name of an attribute to be processed in isolation \")\n\n# startdate \nparser.add_argument('--startdate', '-sd', nargs = 1, required = False, help = \" the first date, as a date-string in form YYYY-MM-DD HH:MM:SS, that you want to process \")\n\n# enddate\nparser.add_argument('--enddate', '-ed', nargs = 1, required = False, help = \" the last date, as a date-string in form YYYY-MM-DD HH:MM:SS, that you want to process \")\n\n# specific probe\nparser.add_argument('--probe', '-p', nargs = 1, required = False, help = \" a single probe, which can be run in isolation \")\n\n# specific station\nparser.add_arguement('--station', nargs=1, required=False, help=\"one station, such as PRIMET, for updates, deletes, and management\")\n\n# new configuration file for mapping specific methods differently\nparser.add_argument('--newcfg', nargs=1, required=False, help = \"follow --newcfg with a .yaml file to be used for configuration rather than the default yaml file\")\n\n# use this arguement to store a csv files\nparser.add_argument('--csv', action='store_true', help = '--csvs will also output csv files', required=False)\n\n# use this arguement to compute VPD using the VPD special control \nparser.add_argument('--vpd', action='store_true', help = \"If --vpd is on, vpd will be calculated with math rather than taken from MS04318. Default is off\", required = False)\n\n# use this arguement to update to the method yaml\nparser.add_arguement('--method', action='store_true', help = \"If --method is on, the methods will be updated based on the input table\")\n\n# use this arguement to run a daily batch file\nparser.add_arguement('--batch', action=\"store-true\", required=False, help=\"if --batch is on, the whole data will be run for 1 day\")\n\n# go!\nargs = parser.parse_args()\n\n# Printing an intro \nprint(\" You are processing using the SMASHER Python toolkit. (c) MIT LICENSCE. 2015. You have given the following information: \\n\")\n \nprint(\"~ Attribute: {}\".format(args.attribute))\nprint(\"~ Server: {}\".format(args.server))\n\nprint(\"~ Start Date: {}\".format(args.startdate))\nprint(\"~ End Date: {}\".format(args.enddate))\n\nprint(\"~ Probe Code: {}\".format(args.probe))\nprint(\"~ New Configuration File: {}\".format(args.newcfg))\n\n\nif args.boss == 'XXDEL'\n\n    print(\" Deleting all data from LTERLogger_Pro for your attribute! \")\n\n    if args.attribute == None:\n        print(\"I cannot process this command without an attribute to delete. Try again :)\")\n\n    else:\n\n        deleteable = args.attribute[0]\n\n        if deleteable == \"AIRTEMP\":\n            full_name = \"LTERLogger_Pro.dbo.MS04301\"\n        elif deleteable == \"RELHUM\":\n            full_name = \"LTERLogger_Pro.dbo.MS04302\"\n        elif deleteable == \"WSPD_PRO\":\n            full_name = \"LTERLogger_Pro.dbo.MS04304\"\n        elif deleteable == \"SOLAR\"\n            full_name = \"LTERLogger_Pro.dbo.MS04305\"\n        elif deleteable == \"PRECIP\":\n            full_name = \"LTERLogger_Pro.dbo.MS04303\"\n        elif deleteable == \"NR\":\n            full_name = \"LTERLogger_Pro.dbo.MS04325\"\n        elif deleteable == \"WSPD_SNC\":\n            full_name = \"LTERLogger_Pro.dbo.MS04324\"\n        elif deleteable == \"SOILWC\":\n            full_name = \"LTERLogger_Pro.dbo.MS04323\"\n        elif deleteable == \"SOILTEMP\":\n            full_name = \"LTERLogger_Pro.dbo.MS04321\"\n        elif deleteable == \"PAR\":\n            full_name = \"LTERLogger_Pro.dbo.MS04322\"\n        elif deletable == \"LYS\":\n            full_name = \"LTERLogger_Pro.dbo.MS04309\"\n        else:\n            print(\"need to create a method to delete {}\".format(deleteable))\n\n\n        # choose the range over which to delete.\n        if args.startdate == None:\n\n            new_query = (\"Delete from \" + full_name + \" where date >= '2014-01-01'\")\n\n        elif args.startdate[0] != None and args.enddate == None:\n            sd = args.startdate[0]\n            new_query = (\"Delete from \" + full_name + \" where date >= \\'\" + sd + \"\\'\")\n\n        elif args.startdate[0] != None and args.enddate[0] != None:\n            sd = args.startdate\n            ed = args.enddate\n\n            new_query = (\"Delete from \" + full_name + \" where date >= \\'\" + sd + \"\\' and date <= \\'\" + ed \"\\'\")\n\n        else:\n            print( \"You have not made a valid combination of start date, end date, and attribute, please try again\")\n\n        import form_connection as fc\n        conn = fc.micro_conn(args.server)\n\n        cursor = conn.cursor()\n\n        cursor.execute(new_query)\n\n        print(\"Your rows have been deleted. You may now try to update again!\")\n\n\nif args.boss == \"LIMITED\":\n\n    if args.attribute == None:\n        print(\" To used the LIMITED function, you need to explicitly provide the single attribute you want to process.\\r The appropriate syntax is: \\n python smasher.py 'LIMITED' 'SHELDON' --attribute 'PRECIP'. This function will only do certin probes from that attribute which are in your limited.yaml file. Start dates and end dates do not need to be input, as they are in the file.\")\n    else:\n        # processes the data only based on the specifics in the LIMITED.yaml file\n        print(\" The smasher will process your LIMITED.yaml file ... Start and Ending dates will be taken from the file, and only your selected probes will be processed... You are doing attribute {} \".format(args.attribute))\n\n        if args.newcfg != None:\n            print(\" SMASHER assumes you want to use the method codes configuration provided in {}\".format(args.newcfg[0]))\n            \n            IterBoss = smashBosses.ProbeBoss(args.attribute[0], args.server).iterate_over_many_config(args.newcfg[0])\n\n            print( \" SMASHER has processed your LIMITED.yaml file \")\n        \n        elif args.newcfg == None:\n            \n            print(\" You did not provide a custom configuration, smasher assumes you want to use CONFIG.yaml \")\n            IterBoss = smashBosses.ProbeBoss(args.attribute[0], args.server).iterate_over_many_config()\n            \n            print(\" smasher has processed your LIMITED.yaml file based on the standard configuration file \")\n\nif args.boss == 'TO-DO':\n    \"\"\" TO-DO is a function to print what needs to be processed. It can take an arguement or not\"\"\"\n    \n    print(\"First, getting the reasonable date ranges for your server, {}\".format(args.server))\n    \n    # get the controller object\n    DBController = smashControls.DBControl(args.server)\n\n    # build queries based on this object\n    DBController.build_queries()\n    \n    # if there is not an attribute specified, then try all the attributes\n    if args.attribute == None:\n        for attribute in [\"AIRTEMP\", \"RELHUM\", \"PRECIP\", \"WSPD_PRO\", \"SOLAR\", \"DEWPT\", \"VPD\", \"LYS\", \"SOILTEMP\", \"PAR\", \"SOILWC\", \"WSPD_SNC\", \"NR\"]:\n\n            # get start and ending dates, if the attribute is up to date, tell us\n            try:\n                sd, ed = DBController.check_out_one_attribute(attribute)\n                print(\" the attribute : \" + attribute + \" needs updates between \" + sd + \" and \" + ed)\n            except AttributeError:\n                print(\" the attribute \" + attribute + \" may already be up to date...\")\n            except KeyError:\n                print(\" the attribute \" + attribute + \" may already be up to date... \")\n    \n    # if an attribute IS specified, then just get that attribute\n    else:\n\n        # get start and ending dates, if the attribute is up to date, tell us\n        # if all lower-case is given, it will be accepted, but the rest may break later.\n        try:\n            sd, ed = DBController.check_out_one_attribute(args.attribute[0].upper())\n            print(\" the attribute : \" + args.attribute[0] + \" needs updates between \" + sd + \" and \" + ed)\n        except AttributeError:\n            print(\" the attribute \" + args.attribute[0] + \" may already be up to date, did you see a message? \")\n        except KeyError:\n            print(\" the attribute \" + args.attribute[0] + \" may already be up to date, did you see a message? \")\n\n\nif args.boss == 'XXDEL1':\n\n    print(\" Deleting all data from LTERLogger_Pro for your attribute! \")\n\n    if args.attribute == None:\n        print(\"I cannot process this command without an attribute to delete. Try again :)\")\n\n    else:\n\n        deleteable = args.attribute[0]\n\n        if deleteable == \"AIRTEMP\":\n            full_name = \"LTERLogger_Pro.dbo.MS04301\"\n        elif deleteable == \"RELHUM\":\n            full_name = \"LTERLogger_Pro.dbo.MS04302\"\n        elif deleteable == \"WSPD_PRO\":\n            full_name = \"LTERLogger_Pro.dbo.MS04304\"\n        elif deleteable == \"SOLAR\"\n            full_name = \"LTERLogger_Pro.dbo.MS04305\"\n        elif deleteable == \"PRECIP\":\n            full_name = \"LTERLogger_Pro.dbo.MS04303\"\n        elif deleteable == \"NR\":\n            full_name = \"LTERLogger_Pro.dbo.MS04325\"\n        elif deleteable == \"WSPD_SNC\":\n            full_name = \"LTERLogger_Pro.dbo.MS04324\"\n        elif deleteable == \"SOILWC\":\n            full_name = \"LTERLogger_Pro.dbo.MS04323\"\n        elif deleteable == \"SOILTEMP\":\n            full_name = \"LTERLogger_Pro.dbo.MS04321\"\n        elif deleteable == \"PAR\":\n            full_name = \"LTERLogger_Pro.dbo.MS04322\"\n        elif deletable == \"LYS\":\n            full_name = \"LTERLogger_Pro.dbo.MS04309\"\n        else:\n            print(\"need to create a method to delete {}\".format(deleteable))\n\n        # choose the range over which to delete.\n        if args.startdate == None:\n\n            new_query = (\"Delete from \" + full_name + \" where sitecode like \" + station + \" and date >= '2014-01-01'\")\n\n        elif args.startdate[0] != None and args.enddate == None:\n            \n            sd = args.startdate[0]\n            new_query = (\"Delete from \" + full_name + \" where sitecode like \" + station + \" and date >= \\'\" + sd + \"\\'\")\n\n        elif args.startdate[0] != None and args.enddate[0] != None:\n            sd = args.startdate\n            ed = args.enddate\n\n            new_query = (\"Delete from \" + full_name + \" where sitecode like \" + station + \" and date >= \\'\" + sd + \"\\' and date <= \\'\" + ed \"\\'\")\n\n        else:\n            print( \"You have not made a valid combination of start date, end date, and attribute, please try again\")\n\n        import form_connection as fc\n        conn = fc.micro_conn(args.server)\n\n        cursor = conn.cursor()\n\n        cursor.execute(new_query)\n\n        print(\"Your rows have been deleted. You may now try to update again!\")\n\n\n# if the provisional arguement is provided, you will update the LTERLogger_Pro\nif args.boss == 'PROVO':\n\n    # update LTERLogger_Pro.dbo.attribute\n    print(\"Updating the provisional database at LTERLogger_Pro\")\n    \n    print(\"Updates come from the source of {}\".format(args.server))\n    my_server = args.server\n\n\n    # if there is one attribute given, you will use it\n    if args.attribute != None:\n\n        # check to be sure the attribute is accepted in our list:\n        if args.attribute[0].upper() not in [\"AIRTEMP\", \"LYS\", \"NR\", \"WSPD_SNC\", \"SOILWC\", \"PAR\", \"SOILTEMP\", \"VPD\", \"DEWPT\", \"SOLAR\", \"WSPD_PRO\", \"PRECIP\", \"RELHUM\"]:\n    \n            print(\"Please use an acceptable attribute such as (upper-case) AIRTEMP, LYS, NR, WSPD_SNC, SOILWC, PAR, SOILTEMP, VPD, DEWPT, SOLAR, WSPD_PRO, PRECIP, or RELHUM\")\n        else:\n\n            pass\n        \n    # if start dates and end dates are given\n    if args.startdate != None and args.enddate != None:\n        \n        # take the start and end dates\n        sd_in = args.startdate[0]\n        ed_in = args.enddate[0]\n\n        try:\n            # create the queries of the most recent updates\n            DBController = smashControls.DBControl(args.server)\n            DBController.build_queries()\n            sd, ed = DBController.check_out_one_attribute(args.attribute[0])\n\n            # check that the input start date does not precede the earliest start date which is already in the DB, otherwise you will write some duplicates\n            if datetime.datetime.strptime(sd_in, '%Y-%m-%d %H:%M:%S') < datetime.datetime.strptime(sd,'%Y-%m-%d %H:%M:%S'):\n                print(\" You cannot perform an insert starting at this time, or you will make duplicate values! I am changing to the newest time you can use, which is {}\".format(sd))\n                ed = ed_in\n            else:\n                sd = sd_in # set the start date value to the inputs\n                ed = ed_in\n\n        except Exception:\n            print(\" The start date check could not be performed. Is there already values in this table?\")\n\n\n        # create an update-boss\n        # if it is VPD, check for the vpd flag indicating we want the \"slow way\"\n        if args.attribute[0] == 'VPD' and args.vpd ==True:\n            U = smashBosses.UpdateBoss(args.attribute[0], sd, ed, args.server, vpd=\"on\")\n        else:\n            U = smashBosses.UpdateBoss(args.attribute[0], sd, ed, args.server)\n        \n        # inserts rows into the database- see the UpdateBoss\n        print \"now we are switching to the SHELDON connection to update LTERLogger_pro\"\n        U.update_the_db()\n\n        # write a csv if it is chosen to do so\n        if args.csv != None:\n            U.write_a_csv()\n        else:\n            pass\n\n        # update the methods based on daily table\n        if args.method != None:\n            U.update_methods\n        else:\n            pass\n\n        # update the flags based on flags table\n        if u.reflags != None;\n\nif args.boss == \"HANS\":\n\n    # take out a connection thread\n    import form_connection as fc\n    conn = fc.micro_conn('SHELDON')\n    # establish a cursor\n    cur = conn.cursor()\n\n    # current day\n    now_day_1 = datetime.datetime.now()\n\n    # the end date is right now, but at midnight of the beginning of today\n    now_day = datetime.datetime(now_day_1.year, now_day_1.month, now_day_1.day, 0, 0)\n\n    ed = datetime.datetime.strftime(now_day,'%Y-%m-%d %H:%M:%S')\n\n    \n    # the start date is the last thing in hte db + 1 day, since we use > = method\n    query = \"select top 1 date from LTERLogger_Pro.dbo.MS04301 order by date desc\"\n    cur.execute(query)\n\n    for row in cur:\n        most_recent_formatted = datetime.datetime.strptime(str(row[0]),'%Y-%m-%d %H:%M:%S') + datetime.timedelta(days = 1)\n\n    sd = most_recent_formatted\n\n    Z = smashBosses.UpdateBoss('AIRTEMP', sd, ed, args.server)\n    Z.update_the_db()\n    print(\"I have processed AIRTEMP for the day!... cleaning myself.\")\n    del Z\n\n    # the start date is the last thing in hte db + 1 day, since we use > = method\n    query = \"select top 1 date from LTERLogger_Pro.dbo.MS04302 order by date desc\"\n    cur.execute(query)\n\n    for row in cur:\n        most_recent_formatted = datetime.datetime.strptime(str(row[0]),'%Y-%m-%d %H:%M:%S') + datetime.timedelta(days = 1)\n\n    sd = most_recent_formatted\n    \n    Z = smashBosses.UpdateBoss('RELHUM', sd, ed, args.server)\n    Z.update_the_db()\n    print(\"I have processed RELHUM for the day!... cleaning myself.\")\n    del Z\n\n    # the start date is the last thing in hte db + 1 day, since we use > = method\n    query = \"select top 1 date from LTERLogger_Pro.dbo.MS04308 order by date desc\"\n    cur.execute(query)\n\n    for row in cur:\n        most_recent_formatted = datetime.datetime.strptime(str(row[0]),'%Y-%m-%d %H:%M:%S') + datetime.timedelta(days = 1)\n\n    sd = most_recent_formatted\n\n    Z = smashBosses.UpdateBoss('VPD', sd, ed, args.server, vpd='on')\n    print(\"Processing VPD-- sorry this one is slow\")\n    Z.update_the_db()\n    print(\"I have processed VPD for the day!... cleaning myself.\")\n    del Z\n\n    # the start date is the last thing in hte db + 1 day, since we use > = method\n    query = \"select top 1 date from LTERLogger_Pro.dbo.MS04307 order by date desc\"\n    cur.execute(query)\n\n    for row in cur:\n        most_recent_formatted = datetime.datetime.strptime(str(row[0]),'%Y-%m-%d %H:%M:%S') + datetime.timedelta(days = 1)\n\n    sd = most_recent_formatted\n\n\n    Z = smashBosses.UpdateBoss('DEWPT', sd, ed, args.server)\n    Z.update_the_db()\n    print(\"I have processed DEWPT for the day!... cleaning myself.\")\n    del Z\n\n    # the start date is the last thing in hte db + 1 day, since we use > = method\n    query = \"select top 1 date from LTERLogger_Pro.dbo.MS04305 order by date desc\"\n    cur.execute(query)\n\n    for row in cur:\n        most_recent_formatted = datetime.datetime.strptime(str(row[0]),'%Y-%m-%d %H:%M:%S') + datetime.timedelta(days = 1)\n\n    sd = most_recent_formatted\n\n    Z = smashBosses.UpdateBoss('SOLAR', sd, ed, args.server)\n    Z.update_the_db()\n    print(\"I have processed SOLAR for the day!... cleaning myself.\")\n    del Z\n\n    # the start date is the last thing in hte db + 1 day, since we use > = method\n    query = \"select top 1 date from LTERLogger_Pro.dbo.MS04321 order by date desc\"\n    cur.execute(query)\n\n    for row in cur:\n        most_recent_formatted = datetime.datetime.strptime(str(row[0]),'%Y-%m-%d %H:%M:%S') + datetime.timedelta(days = 1)\n\n    sd = most_recent_formatted\n\n    Z = smashBosses.UpdateBoss('SOILTEMP', sd, ed, args.server)\n    Z.update_the_db()\n    print(\"I have processed SOILTEMP for the day!... cleaning myself.\")\n    del Z\n\n    # the start date is the last thing in hte db + 1 day, since we use > = method\n    query = \"select top 1 date from LTERLogger_Pro.dbo.MS04304 order by date desc\"\n    cur.execute(query)\n\n    for row in cur:\n        most_recent_formatted = datetime.datetime.strptime(str(row[0]),'%Y-%m-%d %H:%M:%S') + datetime.timedelta(days = 1)\n\n    sd = most_recent_formatted\n\n    Z = smashBosses.UpdateBoss('WSPD_PRO', sd, ed, args.server)\n    Z.update_the_db()\n    print(\"I have processed WINDSPEED PROP for the day!... cleaning myself.\")\n    del Z\n\n    # the start date is the last thing in hte db + 1 day, since we use > = method\n    query = \"select top 1 date from LTERLogger_Pro.dbo.MS04324 order by date desc\"\n    cur.execute(query)\n\n    for row in cur:\n        most_recent_formatted = datetime.datetime.strptime(str(row[0]),'%Y-%m-%d %H:%M:%S') + datetime.timedelta(days = 1)\n\n    sd = most_recent_formatted\n\n    Z = smashBosses.UpdateBoss('WSPD_SNC', sd, ed, args.server)\n    Z.update_the_db()\n    print(\"I have processed WINDSPEED SONIC for the day!... cleaning myself.\")\n    del Z\n\n    # the start date is the last thing in hte db + 1 day, since we use > = method\n    query = \"select top 1 date from LTERLogger_Pro.dbo.MS04303 order by date desc\"\n    cur.execute(query)\n\n    for row in cur:\n        most_recent_formatted = datetime.datetime.strptime(str(row[0]),'%Y-%m-%d %H:%M:%S') + datetime.timedelta(days = 1)\n\n    sd = most_recent_formatted\n\n    Z = smashBosses.UpdateBoss('PRECIP', sd, ed, args.server)\n    Z.update_the_db()\n    print(\"I have processed PRECIP for the day!... cleaning myself.\")\n    del Z\n\n    # the start date is the last thing in hte db + 1 day, since we use > = method\n    query = \"select top 1 date from LTERLogger_Pro.dbo.MS04309 order by date desc\"\n    cur.execute(query)\n\n    for row in cur:\n        most_recent_formatted = datetime.datetime.strptime(str(row[0]),'%Y-%m-%d %H:%M:%S') + datetime.timedelta(days = 1)\n\n    sd = most_recent_formatted\n\n    Z = smashBosses.UpdateBoss('LYS', sd, ed, args.server)\n    Z.update_the_db()\n    print(\"I have processed SNOW LYSIMETER for the day!... cleaning myself.\")\n    del Z\n\n    # the start date is the last thing in hte db + 1 day, since we use > = method\n    query = \"select top 1 date from LTERLogger_Pro.dbo.MS04325 order by date desc\"\n    cur.execute(query)\n\n    for row in cur:\n        most_recent_formatted = datetime.datetime.strptime(str(row[0]),'%Y-%m-%d %H:%M:%S') + datetime.timedelta(days = 1)\n\n    sd = most_recent_formatted\n\n    Z = smashBosses.UpdateBoss('NR', sd, ed, args.server)\n    Z.update_the_db()\n    print(\"I have processed NET RADIATION for the day!... cleaning myself.\")\n    del Z\n\n    # the start date is the last thing in hte db + 1 day, since we use > = method\n    query = \"select top 1 date from LTERLogger_Pro.dbo.MS04322 order by date desc\"\n    cur.execute(query)\n\n    for row in cur:\n        most_recent_formatted = datetime.datetime.strptime(str(row[0]),'%Y-%m-%d %H:%M:%S') + datetime.timedelta(days = 1)\n\n    sd = most_recent_formatted\n\n    Z = smashBosses.UpdateBoss('PAR', sd, ed, args.server)\n    Z.update_the_db()\n    print(\"I have processed PHOTOSYNTHETIC RADIATION for the day!... cleaning myself.\")\n    del Z\n\n    # the start date is the last thing in hte db + 1 day, since we use > = method\n    query = \"select top 1 date from LTERLogger_Pro.dbo.MS04323 order by date desc\"\n    cur.execute(query)\n\n    for row in cur:\n        most_recent_formatted = datetime.datetime.strptime(str(row[0]),'%Y-%m-%d %H:%M:%S') + datetime.timedelta(days = 1)\n\n    sd = most_recent_formatted\n\n    Z = smashBosses.UpdateBoss('SOILWC', sd, ed, args.server)\n    Z.update_the_db()\n    print(\"I have processed SOIL WATER CONTENT for the day!... cleaning myself.\")\n    del Z\n\n    print \"all tables processed\"",
			"file": "smasher.py",
			"file_size": 21886,
			"file_write_time": 1430408163000000,
			"settings":
			{
				"buffer_size": 22025,
				"line_ending": "Unix"
			}
		}
	],
	"build_system": "Packages/Markdown Preview/Markdown.sublime-build",
	"command_palette":
	{
		"height": 347.0,
		"selected_items":
		[
			[
				"Package Control: ",
				"Package Control: Remove Package"
			],
			[
				"",
				"SublimeREPL: Shell"
			],
			[
				"Package Control: instal",
				"Package Control: Install Package"
			],
			[
				"Package Control: install package",
				"Package Control: Install Package"
			],
			[
				"Package Control: inst",
				"Package Control: Install Package"
			],
			[
				"Package Control: insta",
				"Package Control: Install Package"
			],
			[
				"upgrade",
				"Package Control: Upgrade Package"
			],
			[
				"insta",
				"Package Control: Install Package"
			],
			[
				"package conrol",
				"Package Control: Install Package"
			],
			[
				"Package Control: ins",
				"Package Control: Install Package"
			],
			[
				"Package Control: install",
				"Package Control: Install Package"
			],
			[
				"Package Control: inta",
				"Package Control: Install Package"
			],
			[
				"LaTextools",
				"LaTeXTools: Reconfigure and migrate settings"
			],
			[
				"Package Control: remov",
				"Package Control: Remove Package"
			],
			[
				"Snippet: ",
				"Snippet: New Article"
			],
			[
				"repl",
				"SublimeREPL: Matlab"
			],
			[
				"Package Control: Inst",
				"Package Control: Install Package"
			],
			[
				"Package Control: install	",
				"Package Control: Install Package"
			],
			[
				"Package Control: Install Package",
				"Package Control: Install Package"
			]
		],
		"width": 486.0
	},
	"console":
	{
		"height": 124.0
	},
	"distraction_free":
	{
		"menu_visible": true,
		"show_minimap": false,
		"show_open_files": false,
		"show_tabs": false,
		"side_bar_visible": false,
		"status_bar_visible": false
	},
	"file_history":
	[
		"/Users/dataRonin/Documents/may2015/phrsc.txt",
		"/Users/dataRonin/Documents/march2015/airtfx/driver_vanmet.py",
		"/Users/dataRonin/Documents/march2015/airtfx/xtempx.py",
		"/Users/dataRonin/Documents/march2015/airtfx/form_connection.py",
		"/Users/dataRonin/Documents/may2015/wind/templates/highstock.ejs",
		"/Users/dataRonin/Documents/may2015/wind/templates/page.ejs",
		"/Users/dataRonin/Documents/may2015/wind/public/css/foundation.css.map",
		"/Users/dataRonin/Documents/may2015/wind/public/js/app.js",
		"/Users/dataRonin/Documents/april2015/smash/smashWorkers.py",
		"/Users/dataRonin/Documents/april2015/smash/smashBosses.py",
		"/Users/dataRonin/Documents/april2015/smash/CONFIG.yaml",
		"/Users/dataRonin/Documents/april2015/smash/README.md",
		"/Users/dataRonin/Documents/april2015/smash/CONFIG2.yaml",
		"/Users/dataRonin/Documents/april2015/smash/LIMITED.yaml",
		"/Users/dataRonin/Documents/april2015/smash/limited_yaml_bak/LIMITED.yaml",
		"/Users/dataRonin/Documents/april2015/smash/form_connection.py",
		"/Users/dataRonin/Documents/april2015/smash/smash.sublime-project",
		"/Volumes/SHARE/Groups/HJA/phenology/Dataloggers/stream_temperature/cleaned/PC_E1_June2009_Winter13_cleaned_11-2013.csv",
		"/Users/dataRonin/Documents/march2015/sherri/functional_tests.py",
		"/Users/dataRonin/Documents/march2015/sherri/reference_streams/PC_E1_June2009_Winter1311-2013_reformatted.csv",
		"/Users/dataRonin/Documents/march2015/sherri/PC_E1_June2009_Winter13.csv",
		"/Users/dataRonin/Documents/march2015/sherri/tests/unit_tests.py",
		"/Users/dataRonin/Documents/march2015/sherri/config.yaml",
		"/Users/dataRonin/Documents/april2015/refstands/sarah_merge.py",
		"/Users/dataRonin/Documents/january2015/metqc/_posts/2015-03-27-sarahs-reference-stands-temperature-merger.markdown",
		"/Users/dataRonin/Documents/january2015/metqc/_posts/2015-03-27-rescuing-the-reference-stand-data.markdown",
		"/Users/dataRonin/Documents/january2015/metQC/assets/jstest.js",
		"/Users/dataRonin/Documents/january2015/metQC/assets/data.tsv",
		"/Users/dataRonin/Documents/january2015/metQC/_posts/2015-03-25-summary-of-minimum-and-maximum-analyses.markdown",
		"/Users/dataRonin/Documents/march2015/airtfx2/daily_met_latestart.yaml",
		"/Users/dataRonin/Documents/january2015/metQC/_posts/2015-02-10-min_max_checks.markdown",
		"/Users/dataRonin/Documents/january2015/metQC/_posts/_posts/2015-03-24-daily-minimums-and-maximums-can-be-found-from-five-minute-means.markdown",
		"/Users/dataRonin/Documents/january2015/metQC/_posts/2015-03-24-daily-minimums-and-maximums-can-be-found-from-five-minute-means.markdown",
		"/Users/dataRonin/Documents/march2015/airtfx2/sql_primet_150.py",
		"/Users/dataRonin/Documents/march2015/airtfx2/comphrdy.py",
		"/Users/dataRonin/Documents/march2015/airtfx2/hourly_daily_airtemp_primet450.html",
		"/Users/dataRonin/Documents/january2015/metQC/_posts/2015-03-25-rescuing-old-data-from-primet-450.markdown",
		"/Users/dataRonin/Documents/january2015/metQC/octopress",
		"/Users/dataRonin/Documents/january2015/metQC/new",
		"/Users/dataRonin/Documents/january2015/metQC/post",
		"/Users/dataRonin/Documents/january2015/metQC/rescuing old data from PRIMET 450",
		"/Users/dataRonin/codemonkey/_posts/2015-03-25-the-regex-you-must-be-wary-of.markdown",
		"/Users/dataRonin/Documents/march2015/data1.csv",
		"/Users/dataRonin/Documents/march2015/test1.html",
		"/Users/dataRonin/Documents/march2015/airtfx2/functional_tests.py",
		"/Users/dataRonin/Documents/march2015/airtfx2/workflow_vpd.py",
		"/Users/dataRonin/Documents/march2015/airtfx2/workflow.py",
		"/Users/dataRonin/Documents/march2015/airtfx2/workflow_dew.py",
		"/Users/dataRonin/Documents/january2015/metQC/_posts/2015-02-10-comparing-computed-metrics-from-air-temperature-and-relative-humidity.markdown",
		"/Users/dataRonin/Documents/march2015/airtfx2/workflow_airtemp.py",
		"/Users/dataRonin/Documents/march2015/airtfx2/climparser.py",
		"/Users/dataRonin/Documents/march2015/airtfx/CLIM_2014.DAT",
		"/Users/dataRonin/Documents/march2015/airtfx2/CLIM_2015_013.DAT",
		"/Users/dataRonin/Documents/march2015/airtfx2/CLIM_2014.DAT",
		"/Users/dataRonin/Documents/march2015/sherri/setup.py",
		"/Users/dataRonin/cutecat/templates/page.ejs",
		"/Users/dataRonin/renamer.py",
		"/Users/dataRonin/cutecat/app.json",
		"/Users/dataRonin/Library/Application Support/Sublime Text 2/Packages/User/Preferences.sublime-settings",
		"/Users/dataRonin/Documents/march2015/airtfx2/Maximum_solar_downwelling_Wm2.csv",
		"/Users/dataRonin/hurricane/config.toml",
		"/Users/dataRonin/codemonkey/_posts/2015-03-18-review-of-chapters-1-4-of-test-driven-development-in-python.markdown",
		"/Users/dataRonin/codemonkey/_config.yml",
		"/Users/dataRonin/codemonkey/_posts/2015-03-18-template-test.markdown",
		"/Users/dataRonin/Documents/tdd/superlists/functional_tests.py",
		"/Users/dataRonin/Documents/tdd/functional_tests.py",
		"/Users/dataRonin/Documents/march2015/airtfx/ms04318_primet_rebuilt.csv",
		"/Users/dataRonin/.bash_profile",
		"/Users/dataRonin/Documents/tdd/superlists/lists/tests.py",
		"/Users/dataRonin/Documents/march2015/airtfx/driver_cs2met.py",
		"/Users/dataRonin/Documents/march2015/airtfx/driver_h15met.py",
		"/Users/dataRonin/Documents/january2015/metqc/_posts/2015-02-16-validating-dew-point-calculation-versus-portal.markdown",
		"/Users/dataRonin/Documents/march2015/oldxtempx.py",
		"/Users/dataRonin/Documents/march2015/airtfx/driver_fuplmet.py",
		"/Users/dataRonin/Documents/march2015/mapper/schemamap.py",
		"/Users/dataRonin/Documents/march2015/airtfx/driver_cenmet.py",
		"/Users/dataRonin/Documents/march2015/airtfx/driver_uplmet.py",
		"/Users/dataRonin/Documents/march2015/airtfx/driver_aspirated.py",
		"/Users/dataRonin/Documents/march2015/airtfx/driver.py",
		"/Users/dataRonin/Documents/march2015/airtfx/ms04312_uplmet_rebuilt_relhum.csv",
		"/Users/dataRonin/codemonkey/_posts/2015-03-16-speedy-yamling.markdown",
		"/Users/dataRonin/Documents/march2015/pri_conn.py",
		"/.bashrc",
		"/Users/dataRonin/Documents/tdd/superlists/__init__.py",
		"/Users/dataRonin/Documents/tdd/superlists/superlists/__init__.py",
		"/Users/dataRonin/Documents/tdd/superlists/superlists/__pycache__/settings.cpython-34.pyc",
		"/Users/dataRonin/Documents/tdd/superlists/superlists/settings.py",
		"/usr/local/.git/config",
		"/Users/dataRonin/Documents/march2015/vantemp.py",
		"/Users/dataRonin/Documents/january2015/metqc/_posts/2015-03-11-par-what-is-it-and-what-do-we-do-with-it.markdown",
		"/Users/dataRonin/Documents/march2015/despike.py",
		"/Users/dataRonin/Documents/march2015/notes.js",
		"/Users/dataRonin/Documents/march2015/precip/snow.html",
		"/Users/dataRonin/Documents/march2015/cheese3.sql",
		"/Users/dataRonin/Documents/march2015/sqlblob.sql",
		"/Users/dataRonin/Documents/march2015/srdown_15_5.csv",
		"/Users/dataRonin/Documents/march2015/srdown_15_5_primet.csv",
		"/Users/dataRonin/Documents/march2015/cheese2.sql",
		"/Users/dataRonin/Documents/march2015/bignet2.csv",
		"/Users/dataRonin/Documents/march2015/bignet2.cs",
		"/Users/dataRonin/Documents/march2015/bignet.csv",
		"/Users/dataRonin/Documents/march2015/revir.csv",
		"/Users/dataRonin/Documents/march2015/cheese.sql",
		"/Users/dataRonin/Documents/february2015/snopil/baseline.py",
		"/Users/dataRonin/Documents/february2015/litecsv.py",
		"/Users/dataRonin/Documents/february2015/rescuewind.py",
		"/Users/dataRonin/Documents/february2015/snopil/varasno.py",
		"/Users/dataRonin/Documents/january2015/metQC/_posts/2015-02-20-notes-on-5-minute-precip-gage-flags.markdown",
		"/Users/dataRonin/Documents/january2015/metQC/_posts/2015-02-20-checks-on-air-temperature-and-wind-in-portal.markdown",
		"/Users/dataRonin/julia/VERSION",
		"/Users/dataRonin/Documents/february2015/netrad/litecsv.py",
		"/Users/dataRonin/Documents/february2015/uplpre.py",
		"/Users/dataRonin/Documents/january2015/metQC/_posts/2015-02-18-cumulative-precipitation-on-uplmet.markdown",
		"/Users/dataRonin/Documents/january2015/metQC/_posts/2015-02-12-swe-and-sno.markdown",
		"/Users/dataRonin/Documents/january2015/metQC/_posts/2015-02-12-updates-on-snow-lysimeter-and-precipitation-on-uplmet-cenmet-and-h15met.markdown",
		"/Users/dataRonin/codemonkey/_posts/2015-02-18-looking-under-the-sql-hood.markdown",
		"/Users/dataRonin/Documents/february2015/metdatmissing.py",
		"/Users/dataRonin/Documents/february2015/cmdget.c",
		"/Users/dataRonin/Documents/february2015/missing-cenmet.txt",
		"/Users/dataRonin/Documents/february2015/code.sql",
		"/Users/dataRonin/codemonkey/_posts/2015-02-14-code-monkey-subquery.markdown",
		"/Users/dataRonin/Documents/february2015/airtemp/cheese.sql",
		"/Users/dataRonin/Documents/january2015/metQC/_posts/2015-02-08-outline_of_flags_and_problems_on_portal.markdown",
		"/Users/dataRonin/Documents/january2015/metQC/_config.yml",
		"/Users/dataRonin/Documents/february2015/airtemp/datebash.sh",
		"/Users/dataRonin/Documents/january2015/metQC/_posts/2015-02-08-strange-varamet-pattern.markdown",
		"/Users/dataRonin/Downloads/GCE_to_FSDB_checks.md.md",
		"/Users/dataRonin/Documents/january2015/metQC/_posts/2015-02-08-missing-enumeration.markdown"
	],
	"find":
	{
		"height": 92.0
	},
	"find_in_files":
	{
		"height": 0.0,
		"where_history":
		[
			""
		]
	},
	"find_state":
	{
		"case_sensitive": true,
		"find_history":
		[
			"RELHUM",
			"RELNUM",
			"site_code",
			"us: Q",
			"yaml",
			"generate",
			"form",
			"class = right",
			"class= right",
			"class=right",
			"Register",
			"od.keys",
			"\"LYS\"",
			"\"LYS",
			"PAR",
			"SOILTEMP",
			"LTERLogger_new",
			"new",
			"VPD",
			"num_total_obs_spd",
			"print(\"the ",
			"print(\"the nu",
			"height",
			"\"NA",
			"\"None\"",
			"%d",
			"%s",
			"\"None\"",
			"AIR",
			"WND",
			"REL",
			"AIR",
			"max",
			"wuy",
			"wux",
			"dir",
			"daily_flag = 'A'",
			"lwout",
			"lwin",
			"swout",
			"swin",
			"varmet",
			"mean_valid_obs",
			"min_flag",
			"CONFIG",
			"cfg",
			"[288, 96",
			"Rel",
			"Relative",
			"mag",
			"mean",
			"tot",
			"num_not_crappy_obs",
			"flagged_file",
			"site_file",
			"template",
			"gap",
			"walk",
			"\"M\"",
			"\"None",
			"dew",
			"rel",
			"dew",
			"rel",
			"air",
			"minimum",
			"maximum",
			"dewpt",
			"max_val",
			"od_air",
			"[...]",
			"drange",
			"val2ues",
			"val3ues",
			"maximum",
			"flag2",
			"val2",
			"nanmean",
			"flag",
			"val",
			"dew",
			"air",
			"airtemp",
			"'dewpt",
			"G",
			"-30., 50., -20., 45.",
			"dew",
			"Dew",
			"DEW",
			"dewpt",
			"'relhum",
			"dewpti",
			"\"relhum",
			"relhum",
			"C",
			"h15par",
			"fill_gaps_in_dt",
			"parse_dat",
			"parse",
			"REL",
			"dew",
			"relhum",
			"\"relhum\"",
			"RELPRI",
			"val2",
			"h15",
			"-5., 105., -1., 101.",
			"relhum",
			"max",
			"mean",
			"150",
			"sql",
			"h15met",
			"generate",
			"relhum",
			"airtemp",
			"cenmet",
			"generate_min",
			"max",
			"generate_min_max_flags",
			"generate_My",
			"generate_max",
			"fill",
			"generate",
			"adding",
			"min_max_query",
			"generate",
			"cs2met"
		],
		"highlight": true,
		"in_selection": false,
		"preserve_case": false,
		"regex": false,
		"replace_history":
		[
			"self.od.keys",
			"LTERLogger_pro",
			"?",
			"None",
			"REL",
			"AIR",
			"WND",
			"REL",
			"wair",
			"wuy",
			"wux",
			"temp",
			"nr",
			"lwout",
			"lwin",
			"swout",
			"dir",
			"mag",
			"spd",
			"num_valid_obs",
			"\"M",
			"vpd",
			"dew",
			"vpd",
			"dew",
			"rel",
			"min",
			"max",
			"airtemp",
			"min_val",
			"one_dictionary",
			"",
			"values",
			"minimum",
			"flag3",
			"val3",
			"maximum",
			"flag2",
			"val2",
			"vpd",
			"dew",
			"'airtemp",
			"A",
			"-5., 105., -1., 101.",
			"vpd",
			"VPD",
			"vpd",
			"'dewpt",
			"\"dewpt",
			"airtemp",
			"G",
			"DEW",
			"dewpt",
			"\"dewpt\"",
			"AIRPRI0",
			"val3",
			"-35., 50., -20., 45.",
			"airtemp",
			"maximum",
			"max",
			"450",
			"vpd",
			"dewpt",
			"relhum",
			"vpd",
			"dewpt",
			"\"relhum",
			"   ",
			"CuteCat",
			"Cute Cat",
			"D",
			"C",
			"B",
			"\"None\",\"\",\"M\"",
			"\"\",\"A\"",
			", ",
			"",
			", ",
			"\\n* ",
			"\",",
			"",
			"\"",
			"",
			", ",
			"\",",
			"\"2",
			"^\"2",
			"",
			", ",
			" ",
			",",
			"",
			",",
			", 0.",
			"first_year",
			"remeasurements in",
			"self",
			"pi",
			",\"",
			"\",",
			" ",
			"",
			"\", \"",
			"\", \" ",
			", ",
			",",
			"\"",
			"solar_min",
			"intest",
			"v",
			"butt",
			"UPLMET",
			"CS2MET",
			"\\color",
			"&",
			"&{\\cellcolor{yellow}0.6",
			"&{\\cellcolor{yellow}0.7",
			"}&{\\textcolor{blue}0",
			"&{\\cellcolor{yellow}0.5",
			"&{\\cellcolor{yellow}0.6",
			"&{\\cellcolor{yellow}0.7",
			"&",
			"}&{\\textcolor{blue}",
			"AIRH1501",
			"AIRH1502",
			"CS2MET",
			"H15MET",
			"\\color"
		],
		"reverse": false,
		"show_context": true,
		"use_buffer2": true,
		"whole_word": false,
		"wrap": true
	},
	"groups":
	[
		{
			"selected": 0,
			"sheets":
			[
				{
					"buffer": 0,
					"file": "smashWorkers.py",
					"settings":
					{
						"buffer_size": 262152,
						"regions":
						{
						},
						"selection":
						[
							[
								12057,
								12057
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.tmLanguage",
							"tab_size": 4,
							"translate_tabs_to_spaces": true,
							"word_wrap": true
						},
						"translation.x": 0.0,
						"translation.y": 4321.0,
						"zoom_level": 1.0
					},
					"type": "text"
				},
				{
					"buffer": 1,
					"file": "smashBosses.py",
					"settings":
					{
						"buffer_size": 20824,
						"regions":
						{
						},
						"selection":
						[
							[
								8410,
								8410
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.tmLanguage",
							"tab_size": 4,
							"translate_tabs_to_spaces": true,
							"word_wrap": true
						},
						"translation.x": 0.0,
						"translation.y": 3046.0,
						"zoom_level": 1.0
					},
					"type": "text"
				},
				{
					"buffer": 2,
					"file": "smashControls.py",
					"settings":
					{
						"buffer_size": 21434,
						"regions":
						{
						},
						"selection":
						[
							[
								21434,
								21434
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.tmLanguage",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 6770.0,
						"zoom_level": 1.0
					},
					"type": "text"
				},
				{
					"buffer": 3,
					"file": "smasher.py",
					"settings":
					{
						"buffer_size": 22025,
						"regions":
						{
						},
						"selection":
						[
							[
								506,
								506
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.tmLanguage",
							"tab_size": 4,
							"translate_tabs_to_spaces": true,
							"word_wrap": true
						},
						"translation.x": 0.0,
						"translation.y": 4642.0,
						"zoom_level": 1.0
					},
					"type": "text"
				}
			]
		}
	],
	"incremental_find":
	{
		"height": 34.0
	},
	"input":
	{
		"height": 34.0
	},
	"layout":
	{
		"cells":
		[
			[
				0,
				0,
				1,
				1
			]
		],
		"cols":
		[
			0.0,
			1.0
		],
		"rows":
		[
			0.0,
			1.0
		]
	},
	"menu_visible": true,
	"output.exec":
	{
		"height": 106.0
	},
	"output.latex_log":
	{
		"height": 28.0
	},
	"output.markdown":
	{
		"height": 91.0
	},
	"replace":
	{
		"height": 66.0
	},
	"save_all_on_build": true,
	"select_file":
	{
		"height": 0.0,
		"selected_items":
		[
		],
		"width": 0.0
	},
	"select_project":
	{
		"height": 0.0,
		"selected_items":
		[
		],
		"width": 0.0
	},
	"show_minimap": false,
	"show_open_files": true,
	"show_tabs": true,
	"side_bar_visible": true,
	"side_bar_width": 126.0,
	"status_bar_visible": true
}
